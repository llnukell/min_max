def minimax_alpha_beta(self, maximizing_player, temp_board, depth, color, alpha, beta):

    all_moves_and_pieces = self.get_all_valid_moves_game(color, temp_board, pawn_special_flag=None)

    if depth == 0:
        evaluation = self.minmax_evaluate_board(temp_board)
        return evaluation, color

    if color == 'white':
        max_eval = -1000
        for white_piece, white_moves in all_moves_and_pieces:
            for white_move in white_moves:

                temp_board_white = copy.deepcopy(temp_board)
                temp_board.move(white_piece, white_move, TURN=0, rules_flag=0, monitor=None)
                color = 'black'
                evaluation, color = self.minimax_alpha_beta(maximizing_player, temp_board, (depth - 1), color, alpha, beta)

                # Return from [2] - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
                temp_board = copy.deepcopy(temp_board_white)

                if evaluation > max_eval:
                    max_eval = evaluation
                    if maximizing_player == 'white':
                        self.best_move = white_move
                        self.best_piece = white_piece

                alpha = max(alpha, evaluation)
                if beta <= alpha:
                    break

        temp_board = copy.deepcopy(self.board)

        # --- END OF METHOD --- / 1
        return max_eval, color
    
    elif color == 'black':
        min_eval = 1000
        for black_piece, black_moves in all_moves_and_pieces:
            for black_move in black_moves:

                temp_board_black = copy.deepcopy(temp_board)
                temp_board.move(black_piece, black_move, TURN=0, rules_flag=0, monitor=None)
                color = 'white'
                evaluation, color = self.minimax_alpha_beta(maximizing_player, temp_board, (depth - 1), color, alpha, beta)

                # Return from [1] - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
                temp_board = copy.deepcopy(temp_board_black)

                if evaluation < min_eval:
                    min_eval = evaluation
                    if maximizing_player == 'black':
                        self.best_move = black_move
                        self.best_piece = black_piece

                beta = min(beta, evaluation)
                if beta <= alpha:
                    break

        temp_board = copy.deepcopy(self.board)
        
        # --- END OF METHOD --- / 2
        return min_eval, color
		
=================================================================================================================

Implementation:

def main_engine(self, TURN, White_Points, Black_Points):

    all_moves_and_pieces = self.board.get_all_valid_moves(self.next_player, pawn_special_flag)

    if all_moves_and_pieces:

        depth = 2
        color = self.next_player
        temp_board = copy.deepcopy(self.board)
        
        best_eval = self.minimax_alpha_beta(temp_board, all_moves_and_pieces, depth, color, alpha=-1000, beta=1000)
        best_move = self.best_move
        best_piece = self.best_piece

        self.board.move(best_piece, best_move, TURN, rules_flag=0, monitor=None)
        self.store_played_moves(best_move)

    return TURN, White_Points, Black_Points
